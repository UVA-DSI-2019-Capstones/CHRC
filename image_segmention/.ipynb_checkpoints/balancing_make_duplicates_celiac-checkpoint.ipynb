{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from pandas import DataFrame, Series\n",
    "from PIL import Image\n",
    "import timeit\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHANGE THESE TO POINT TO VALID AND TRAIN FOR ALL CATEGORIES\n",
    "## PRESERVE THE ORDER\n",
    "train_paths = [\"../data_segments/data_balanced_duplicate_sample/valid/Celiac\", \"../data_segments/data_balanced_duplicate_sample/valid/EE\", \n",
    "               \"../data_segments/data_balanced_duplicate_sample/valid/Normal\", \"../data_segments/data_balanced_duplicate_sample/train/Celiac\", \n",
    "               \"../data_segments/data_balanced_duplicate_sample/train/EE\", \"../data_segments/data_balanced_duplicate_sample/train/Normal\"]\n",
    "\n",
    "images = {}\n",
    "images_by_folder = {}\n",
    "for train_path in train_paths:\n",
    "    images_by_folder[str(train_path)] = []\n",
    "    files = glob.glob(os.path.join(train_path, '*.jpg'))\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        flbase_noext = os.path.splitext(flbase)[0]\n",
    "        images[flbase_noext]=fl\n",
    "        images_by_folder[str(train_path)].append(flbase_noext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "# CHANGE THESE PATHS TO POINT TO TRAIN AND VALID FOLDER FOR CELIAC RESPECTIVELY \n",
    "train_paths = [\"../data_segments/chrc_data_segments/train/Celiac\"]\n",
    "valid_paths = [\"../data_segments/chrc_data_segments/valid/Celiac\"]\n",
    "\n",
    "\n",
    "## CHANGE THESE TO POINT TO TRAIN AND VALID FOLDER WITH THE MAXIMUM NUMBER OF FILES IN BOTH\n",
    "## EXAMPLE CHANGE max_train PATH TO POINT TO train/EE or train/Celiac or train/Normal. WHICHEVER HAS MAXIMUM NUMBER OF FILES\n",
    "## SIMILARLY FOR max_valid. BOTH COULD POINT TO DIFFERENT CATEGORIES!\n",
    "### MAKE SURE THESE ARE THE SAME IN ALL THREE SCRIPTS\n",
    "max_train = len(images_by_folder[\"../data_segments/chrc_data_segments/train/EE\"])\n",
    "max_valid = len(images_by_folder[\"../data_segments/chrc_data_segments/valid/EE\"])\n",
    "\n",
    "for path in train_paths:\n",
    "    mult = int(round(max_train / len(images_by_folder[str(path)])))\n",
    "    print (str(path) + \" Multiply index: \" + str(mult) + \" Original SIze:  \" + str(len(images_by_folder[str(path)])))\n",
    "    counter = 0\n",
    "    for img in images_by_folder[str(path)]:\n",
    "        counter = counter + 1\n",
    "        if (counter % 10000 == 0):\n",
    "            print(counter)\n",
    "        src = str(path) + \"/\" + str(img)  + '.jpg'\n",
    "#         dst = '../data_segments/' + 'data_balanced_duplicate_sample/' + str(path.split('/')[-2].strip()) + '/' + str(path.split('/')[-1].strip()) + '/' + str(img)\n",
    "        for i in range(mult):\n",
    "            dst = '../data_segments/' + 'data_balanced_duplicate_sample/' + str(path.split('/')[-2].strip()) + '/' + str(path.split('/')[-1].strip()) + '/' + str(img) + '_' + str(i) + '.jpg'\n",
    "            copyfile(src, dst)\n",
    "            \n",
    "print ('Doing Valid now!')\n",
    "for path in valid_paths:\n",
    "    mult = int(round(max_valid / len(images_by_folder[str(path)])))\n",
    "    print (str(path) + \" Multiply index: \" + str(mult) + \" Original SIze:  \" + str(len(images_by_folder[str(path)])))\n",
    "    counter = 0\n",
    "    for img in images_by_folder[str(path)]:\n",
    "        counter = counter + 1\n",
    "        if (counter % 10000 == 0):\n",
    "            print(counter)\n",
    "        src = str(path) + \"/\" + str(img) + '.jpg'\n",
    "#         dst = '../data_segments/' + 'data_balanced_duplicate_sample/' + str(path.split('/')[-2].strip()) + '/' + str(path.split('/')[-1].strip()) + '/' + str(img) \n",
    "        for i in range(mult):\n",
    "            dst = '../data_segments/' + 'data_balanced_duplicate_sample/' + str(path.split('/')[-2].strip()) + '/' + str(path.split('/')[-1].strip()) + '/' + str(img) + '_' + str(i) + '.jpg'\n",
    "            copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in train_paths:\n",
    "    print (p)\n",
    "    print (len(images_by_folder[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
