{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the main external libs we'll use\n",
    "import fastai\n",
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch \n",
    "import numpy \n",
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "from fastai import conv_learner\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for respective architectures\n",
    "arch1 = resnet34\n",
    "PATH1 = \"../../CHRC_NEW_DATA/chrc_data_patches_norm_1000_dup/\"\n",
    "sz1=512\n",
    "\n",
    "\n",
    "arch2=resnet50\n",
    "PATH2 = \"../../CHRC_NEW_DATA/chrc_data_patches_norm_duplicated/\"\n",
    "sz2=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = ImageClassifierData.from_paths(PATH1, tfms=tfms_from_model(arch1, sz1))\n",
    "learn1 = ConvLearner.pretrained(arch1, data1, precompute=False)\n",
    "learn1.precompute = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = ImageClassifierData.from_paths(PATH2, tfms=tfms_from_model(arch2, sz2))\n",
    "learn2 = ConvLearner.pretrained(arch2, data2, precompute=False)\n",
    "learn2.precompute = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tMissing key(s) in state_dict: \"1.weight\", \"1.bias\", \"1.running_mean\", \"1.running_var\", \"4.0.conv1.weight\", \"4.0.bn1.weight\", \"4.0.bn1.bias\", \"4.0.bn1.running_mean\", \"4.0.bn1.running_var\", \"4.0.conv2.weight\", \"4.0.bn2.weight\", \"4.0.bn2.bias\", \"4.0.bn2.running_mean\", \"4.0.bn2.running_var\", \"4.1.conv1.weight\", \"4.1.bn1.weight\", \"4.1.bn1.bias\", \"4.1.bn1.running_mean\", \"4.1.bn1.running_var\", \"4.1.conv2.weight\", \"4.1.bn2.weight\", \"4.1.bn2.bias\", \"4.1.bn2.running_mean\", \"4.1.bn2.running_var\", \"4.2.conv1.weight\", \"4.2.bn1.weight\", \"4.2.bn1.bias\", \"4.2.bn1.running_mean\", \"4.2.bn1.running_var\", \"4.2.conv2.weight\", \"4.2.bn2.weight\", \"4.2.bn2.bias\", \"4.2.bn2.running_mean\", \"4.2.bn2.running_var\", \"5.0.conv1.weight\", \"5.0.bn1.weight\", \"5.0.bn1.bias\", \"5.0.bn1.running_mean\", \"5.0.bn1.running_var\", \"5.0.conv2.weight\", \"5.0.bn2.weight\", \"5.0.bn2.bias\", \"5.0.bn2.running_mean\", \"5.0.bn2.running_var\", \"5.0.downsample.0.weight\", \"5.0.downsample.1.weight\", \"5.0.downsample.1.bias\", \"5.0.downsample.1.running_mean\", \"5.0.downsample.1.running_var\", \"5.1.conv1.weight\", \"5.1.bn1.weight\", \"5.1.bn1.bias\", \"5.1.bn1.running_mean\", \"5.1.bn1.running_var\", \"5.1.conv2.weight\", \"5.1.bn2.weight\", \"5.1.bn2.bias\", \"5.1.bn2.running_mean\", \"5.1.bn2.running_var\", \"5.2.conv1.weight\", \"5.2.bn1.weight\", \"5.2.bn1.bias\", \"5.2.bn1.running_mean\", \"5.2.bn1.running_var\", \"5.2.conv2.weight\", \"5.2.bn2.weight\", \"5.2.bn2.bias\", \"5.2.bn2.running_mean\", \"5.2.bn2.running_var\", \"5.3.conv1.weight\", \"5.3.bn1.weight\", \"5.3.bn1.bias\", \"5.3.bn1.running_mean\", \"5.3.bn1.running_var\", \"5.3.conv2.weight\", \"5.3.bn2.weight\", \"5.3.bn2.bias\", \"5.3.bn2.running_mean\", \"5.3.bn2.running_var\", \"6.0.conv1.weight\", \"6.0.bn1.weight\", \"6.0.bn1.bias\", \"6.0.bn1.running_mean\", \"6.0.bn1.running_var\", \"6.0.conv2.weight\", \"6.0.bn2.weight\", \"6.0.bn2.bias\", \"6.0.bn2.running_mean\", \"6.0.bn2.running_var\", \"6.0.downsample.0.weight\", \"6.0.downsample.1.weight\", \"6.0.downsample.1.bias\", \"6.0.downsample.1.running_mean\", \"6.0.downsample.1.running_var\", \"6.1.conv1.weight\", \"6.1.bn1.weight\", \"6.1.bn1.bias\", \"6.1.bn1.running_mean\", \"6.1.bn1.running_var\", \"6.1.conv2.weight\", \"6.1.bn2.weight\", \"6.1.bn2.bias\", \"6.1.bn2.running_mean\", \"6.1.bn2.running_var\", \"6.2.conv1.weight\", \"6.2.bn1.weight\", \"6.2.bn1.bias\", \"6.2.bn1.running_mean\", \"6.2.bn1.running_var\", \"6.2.conv2.weight\", \"6.2.bn2.weight\", \"6.2.bn2.bias\", \"6.2.bn2.running_mean\", \"6.2.bn2.running_var\", \"6.3.conv1.weight\", \"6.3.bn1.weight\", \"6.3.bn1.bias\", \"6.3.bn1.running_mean\", \"6.3.bn1.running_var\", \"6.3.conv2.weight\", \"6.3.bn2.weight\", \"6.3.bn2.bias\", \"6.3.bn2.running_mean\", \"6.3.bn2.running_var\", \"6.4.conv1.weight\", \"6.4.bn1.weight\", \"6.4.bn1.bias\", \"6.4.bn1.running_mean\", \"6.4.bn1.running_var\", \"6.4.conv2.weight\", \"6.4.bn2.weight\", \"6.4.bn2.bias\", \"6.4.bn2.running_mean\", \"6.4.bn2.running_var\", \"6.5.conv1.weight\", \"6.5.bn1.weight\", \"6.5.bn1.bias\", \"6.5.bn1.running_mean\", \"6.5.bn1.running_var\", \"6.5.conv2.weight\", \"6.5.bn2.weight\", \"6.5.bn2.bias\", \"6.5.bn2.running_mean\", \"6.5.bn2.running_var\", \"7.0.conv1.weight\", \"7.0.bn1.weight\", \"7.0.bn1.bias\", \"7.0.bn1.running_mean\", \"7.0.bn1.running_var\", \"7.0.conv2.weight\", \"7.0.bn2.weight\", \"7.0.bn2.bias\", \"7.0.bn2.running_mean\", \"7.0.bn2.running_var\", \"7.0.downsample.0.weight\", \"7.0.downsample.1.weight\", \"7.0.downsample.1.bias\", \"7.0.downsample.1.running_mean\", \"7.0.downsample.1.running_var\", \"7.1.conv1.weight\", \"7.1.bn1.weight\", \"7.1.bn1.bias\", \"7.1.bn1.running_mean\", \"7.1.bn1.running_var\", \"7.1.conv2.weight\", \"7.1.bn2.weight\", \"7.1.bn2.bias\", \"7.1.bn2.running_mean\", \"7.1.bn2.running_var\", \"7.2.conv1.weight\", \"7.2.bn1.weight\", \"7.2.bn1.bias\", \"7.2.bn1.running_mean\", \"7.2.bn1.running_var\", \"7.2.conv2.weight\", \"7.2.bn2.weight\", \"7.2.bn2.bias\", \"7.2.bn2.running_mean\", \"7.2.bn2.running_var\", \"10.weight\", \"10.bias\", \"10.running_mean\", \"10.running_var\", \"12.weight\", \"12.bias\", \"14.weight\", \"14.bias\", \"14.running_mean\", \"14.running_var\", \"16.weight\", \"16.bias\". \n\tUnexpected key(s) in state_dict: \"0.bias\", \"0.running_mean\", \"0.running_var\", \"0.num_batches_tracked\", \"2.weight\", \"2.bias\", \"4.weight\", \"4.bias\", \"4.running_mean\", \"4.running_var\", \"4.num_batches_tracked\", \"6.weight\", \"6.bias\". \n\tsize mismatch for 0.weight: copying a param of torch.Size([64, 3, 7, 7]) from checkpoint, where the shape is torch.Size([1024]) in current model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-197fbe5c0662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1000x1000_lastlayer_resnet34_lowres_staintools'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/sfs/lustre/scratch/as3ek/CHRC/models/fastai/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swa_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-swa.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/sfs/lustre/scratch/as3ek/CHRC/models/fastai/torch_imports.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(m, p)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_raw'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_raw'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 719\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Sequential:\n\tMissing key(s) in state_dict: \"1.weight\", \"1.bias\", \"1.running_mean\", \"1.running_var\", \"4.0.conv1.weight\", \"4.0.bn1.weight\", \"4.0.bn1.bias\", \"4.0.bn1.running_mean\", \"4.0.bn1.running_var\", \"4.0.conv2.weight\", \"4.0.bn2.weight\", \"4.0.bn2.bias\", \"4.0.bn2.running_mean\", \"4.0.bn2.running_var\", \"4.1.conv1.weight\", \"4.1.bn1.weight\", \"4.1.bn1.bias\", \"4.1.bn1.running_mean\", \"4.1.bn1.running_var\", \"4.1.conv2.weight\", \"4.1.bn2.weight\", \"4.1.bn2.bias\", \"4.1.bn2.running_mean\", \"4.1.bn2.running_var\", \"4.2.conv1.weight\", \"4.2.bn1.weight\", \"4.2.bn1.bias\", \"4.2.bn1.running_mean\", \"4.2.bn1.running_var\", \"4.2.conv2.weight\", \"4.2.bn2.weight\", \"4.2.bn2.bias\", \"4.2.bn2.running_mean\", \"4.2.bn2.running_var\", \"5.0.conv1.weight\", \"5.0.bn1.weight\", \"5.0.bn1.bias\", \"5.0.bn1.running_mean\", \"5.0.bn1.running_var\", \"5.0.conv2.weight\", \"5.0.bn2.weight\", \"5.0.bn2.bias\", \"5.0.bn2.running_mean\", \"5.0.bn2.running_var\", \"5.0.downsample.0.weight\", \"5.0.downsample.1.weight\", \"5.0.downsample.1.bias\", \"5.0.downsample.1.running_mean\", \"5.0.downsample.1.running_var\", \"5.1.conv1.weight\", \"5.1.bn1.weight\", \"5.1.bn1.bias\", \"5.1.bn1.running_mean\", \"5.1.bn1.running_var\", \"5.1.conv2.weight\", \"5.1.bn2.weight\", \"5.1.bn2.bias\", \"5.1.bn2.running_mean\", \"5.1.bn2.running_var\", \"5.2.conv1.weight\", \"5.2.bn1.weight\", \"5.2.bn1.bias\", \"5.2.bn1.running_mean\", \"5.2.bn1.running_var\", \"5.2.conv2.weight\", \"5.2.bn2.weight\", \"5.2.bn2.bias\", \"5.2.bn2.running_mean\", \"5.2.bn2.running_var\", \"5.3.conv1.weight\", \"5.3.bn1.weight\", \"5.3.bn1.bias\", \"5.3.bn1.running_mean\", \"5.3.bn1.running_var\", \"5.3.conv2.weight\", \"5.3.bn2.weight\", \"5.3.bn2.bias\", \"5.3.bn2.running_mean\", \"5.3.bn2.running_var\", \"6.0.conv1.weight\", \"6.0.bn1.weight\", \"6.0.bn1.bias\", \"6.0.bn1.running_mean\", \"6.0.bn1.running_var\", \"6.0.conv2.weight\", \"6.0.bn2.weight\", \"6.0.bn2.bias\", \"6.0.bn2.running_mean\", \"6.0.bn2.running_var\", \"6.0.downsample.0.weight\", \"6.0.downsample.1.weight\", \"6.0.downsample.1.bias\", \"6.0.downsample.1.running_mean\", \"6.0.downsample.1.running_var\", \"6.1.conv1.weight\", \"6.1.bn1.weight\", \"6.1.bn1.bias\", \"6.1.bn1.running_mean\", \"6.1.bn1.running_var\", \"6.1.conv2.weight\", \"6.1.bn2.weight\", \"6.1.bn2.bias\", \"6.1.bn2.running_mean\", \"6.1.bn2.running_var\", \"6.2.conv1.weight\", \"6.2.bn1.weight\", \"6.2.bn1.bias\", \"6.2.bn1.running_mean\", \"6.2.bn1.running_var\", \"6.2.conv2.weight\", \"6.2.bn2.weight\", \"6.2.bn2.bias\", \"6.2.bn2.running_mean\", \"6.2.bn2.running_var\", \"6.3.conv1.weight\", \"6.3.bn1.weight\", \"6.3.bn1.bias\", \"6.3.bn1.running_mean\", \"6.3.bn1.running_var\", \"6.3.conv2.weight\", \"6.3.bn2.weight\", \"6.3.bn2.bias\", \"6.3.bn2.running_mean\", \"6.3.bn2.running_var\", \"6.4.conv1.weight\", \"6.4.bn1.weight\", \"6.4.bn1.bias\", \"6.4.bn1.running_mean\", \"6.4.bn1.running_var\", \"6.4.conv2.weight\", \"6.4.bn2.weight\", \"6.4.bn2.bias\", \"6.4.bn2.running_mean\", \"6.4.bn2.running_var\", \"6.5.conv1.weight\", \"6.5.bn1.weight\", \"6.5.bn1.bias\", \"6.5.bn1.running_mean\", \"6.5.bn1.running_var\", \"6.5.conv2.weight\", \"6.5.bn2.weight\", \"6.5.bn2.bias\", \"6.5.bn2.running_mean\", \"6.5.bn2.running_var\", \"7.0.conv1.weight\", \"7.0.bn1.weight\", \"7.0.bn1.bias\", \"7.0.bn1.running_mean\", \"7.0.bn1.running_var\", \"7.0.conv2.weight\", \"7.0.bn2.weight\", \"7.0.bn2.bias\", \"7.0.bn2.running_mean\", \"7.0.bn2.running_var\", \"7.0.downsample.0.weight\", \"7.0.downsample.1.weight\", \"7.0.downsample.1.bias\", \"7.0.downsample.1.running_mean\", \"7.0.downsample.1.running_var\", \"7.1.conv1.weight\", \"7.1.bn1.weight\", \"7.1.bn1.bias\", \"7.1.bn1.running_mean\", \"7.1.bn1.running_var\", \"7.1.conv2.weight\", \"7.1.bn2.weight\", \"7.1.bn2.bias\", \"7.1.bn2.running_mean\", \"7.1.bn2.running_var\", \"7.2.conv1.weight\", \"7.2.bn1.weight\", \"7.2.bn1.bias\", \"7.2.bn1.running_mean\", \"7.2.bn1.running_var\", \"7.2.conv2.weight\", \"7.2.bn2.weight\", \"7.2.bn2.bias\", \"7.2.bn2.running_mean\", \"7.2.bn2.running_var\", \"10.weight\", \"10.bias\", \"10.running_mean\", \"10.running_var\", \"12.weight\", \"12.bias\", \"14.weight\", \"14.bias\", \"14.running_mean\", \"14.running_var\", \"16.weight\", \"16.bias\". \n\tUnexpected key(s) in state_dict: \"0.bias\", \"0.running_mean\", \"0.running_var\", \"0.num_batches_tracked\", \"2.weight\", \"2.bias\", \"4.weight\", \"4.bias\", \"4.running_mean\", \"4.running_var\", \"4.num_batches_tracked\", \"6.weight\", \"6.bias\". \n\tsize mismatch for 0.weight: copying a param of torch.Size([64, 3, 7, 7]) from checkpoint, where the shape is torch.Size([1024]) in current model."
     ]
    }
   ],
   "source": [
    "learn1.load('1000x1000_lastlayer_resnet34_lowres_staintools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn2.load('resnet50_new_patches_3000_staintools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mp): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (9): Flatten()\n",
       "  (10): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): Dropout(p=0.25)\n",
       "  (12): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (13): ReLU()\n",
       "  (14): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): Dropout(p=0.5)\n",
       "  (16): Linear(in_features=512, out_features=3, bias=True)\n",
       "  (17): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn2.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures:\n",
    "    def __init__(self, m):\n",
    "        self.handle = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, m, inp, outp):\n",
    "        self.features = outp\n",
    "    def remove(self):\n",
    "        self.handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = [SaveFeatures(m) for m in [learn2[8], learn2[16]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(data2.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 512, 512])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSaver:\n",
    "    def __init__(self, learner, tmp_path, data):\n",
    "        self.learner = learner\n",
    "        self.tmp_path = tmp_path\n",
    "        self.m = learner.models.model\n",
    "        self.sf = [SaveFeatures(m1) for m1 in [self.m[8], self.m[16]]]\n",
    "        self.data = data\n",
    "        self.first_step()\n",
    "    \n",
    "    def first_step(self):\n",
    "        self.m.eval()\n",
    "        x, y = next(iter(data.trn_dl))\n",
    "        y = self.m(V(x))\n",
    "        return\n",
    "        \n",
    "    def create_feat_empty_bcolz(self, nf, name):\n",
    "        return bcolz.carray(np.zeros(nf, np.float32), chunklen=1, mode='w', rootdir=name)\n",
    "\n",
    "    def get_activations_holder(self, tmpl, nf=None, force=False):\n",
    "        #tmpl = f'_{self.models.name}_{self.data.sz}.bc'\n",
    "        names = [os.path.join(self.tmp_path, p+tmpl) for p in ('x_act', 'x_act_val', 'x_act_test')]\n",
    "        if os.path.exists(names[0]) and not force:\n",
    "            activations = [bcolz.open(p) for p in names]\n",
    "        else:\n",
    "            activations = [self.create_feat_empty_bcolz(nf, n) for n in names]\n",
    "        return activations\n",
    "\n",
    "    def save_features_mdl(self, idx, tmpl):\n",
    "        nf = self.sf[idx].features.shape\n",
    "#         nf = len(self.sf[idx].features)\n",
    "        actv = self.get_activations_holder(tmpl, nf, force=True)\n",
    "        tr_act, val_act, test_act = actv\n",
    "        if len(actv[0])!=len(self.data.trn_ds):\n",
    "            self.predict_feat_to_bcolz(idx, self.data.fix_dl, tr_act)\n",
    "        if len(actv[1])!=len(self.data.val_ds):\n",
    "            self.predict_feat_to_bcolz(idx, self.data.val_dl, val_act)\n",
    "        if self.data.test_dl and (len(actv[2])!=len(self.data.test_ds)):\n",
    "            if self.data.test_dl: self.predict_feat_to_bcolz(idx, self.data.test_dl, test_act)\n",
    "                \n",
    "    def predict_feat_to_bcolz(self, idx, gen, arr):\n",
    "        arr.trim(len(arr))\n",
    "        lock=threading.Lock()\n",
    "        self.m.eval()\n",
    "        print('Starting now')\n",
    "        for x, _ in tqdm(gen):\n",
    "            y = self.m(V(x))\n",
    "            o1 = to_np(self.sf[idx].features)\n",
    "            with lock:\n",
    "                arr.append(o1)\n",
    "                arr.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpl = 'x_act_resnet50_0_512.bc'\n",
    "feat_saver = FeatureSaver(learn2, f'{PATH2}tmp', data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting now\n",
      "100%|██████████| 154/154 [08:21<00:00,  2.32s/it]\n",
      "Starting now\n",
      "100%|██████████| 41/41 [02:19<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "feat_saver.save_features_mdl(1, tmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\ttmp  train  valid\r\n"
     ]
    }
   ],
   "source": [
    "!ls {PATH2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Bottom(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ResNet50Bottom, self).__init__()\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-8])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "res50_conv2 = ResNet50Bottom(learn2.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(data2.trn_dl)\n",
    "inputs, labels = next(i)\n",
    "inputs, labels = Variable(inputs), Variable(labels)\n",
    "outputs = res50_conv2(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9819"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2.trn_dl.dataset.fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4096])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5471, 1.9567, 1.4873,  ..., 0.2694, 0.1216, 0.3571], device='cuda:0')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8885, 3.4051, 1.9177,  ..., 0.5425, 0.2665, 0.6057], device='cuda:0')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, labels = next(i)\n",
    "inputs, labels = Variable(inputs), Variable(labels)\n",
    "outputs = res50_conv2(inputs)\n",
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "send() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-ff04a95628ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: send() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "i.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(data2.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [64, 3, 7, 7], but got input of size [3, 512, 512] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-5617902a0f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres50_conv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget1item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-35c4c6e66c2d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [64, 3, 7, 7], but got input of size [3, 512, 512] instead"
     ]
    }
   ],
   "source": [
    "res50_conv2(Variable(V(data2.trn_dl.get_batch([9818])[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.65136,  1.59942,  1.43624, ...,  0.93642,  1.17164,  0.75017],\n",
       "        [ 1.38131,  1.41287,  1.16173, ...,  0.94259,  0.8877 ,  0.11419],\n",
       "        [ 1.2332 ,  1.11449,  1.39986, ...,  0.73916,  0.68656,  0.19979],\n",
       "        ...,\n",
       "        [ 2.23416,  2.23951,  2.22591, ...,  2.23541,  2.23908,  2.22926],\n",
       "        [ 2.22168,  2.23207,  2.22627, ...,  2.23016,  2.23426,  2.22651],\n",
       "        [ 2.22473,  2.22475,  2.23496, ...,  2.23063,  2.22432,  2.23869]],\n",
       "\n",
       "       [[ 0.9711 ,  0.93752,  0.5783 , ..., -0.31907,  0.08526, -0.34831],\n",
       "        [ 0.45204,  0.40131,  0.08633, ..., -0.32827, -0.38344, -1.0391 ],\n",
       "        [ 0.16897,  0.02024,  0.54729, ..., -0.57599, -0.60046, -1.01487],\n",
       "        ...,\n",
       "        [ 2.41349,  2.41896,  2.40506, ...,  2.41477,  2.41852,  2.40848],\n",
       "        [ 2.40074,  2.41136,  2.40279, ...,  2.4094 ,  2.41046,  2.39499],\n",
       "        [ 2.40386,  2.40387,  2.40569, ...,  2.40989,  2.39188,  2.38945]],\n",
       "\n",
       "       [[ 2.14987,  2.10124,  1.96512, ...,  1.58498,  1.80771,  1.10032],\n",
       "        [ 1.92498,  1.99289,  1.72249, ...,  1.57641,  1.47394,  0.37272],\n",
       "        [ 1.83021,  1.64149,  1.90784, ...,  1.28897,  1.18914,  0.44842],\n",
       "        ...,\n",
       "        [ 2.62499,  2.63043,  2.6166 , ...,  2.62626,  2.63   ,  2.62   ],\n",
       "        [ 2.61229,  2.62287,  2.61758, ...,  2.62091,  2.62525,  2.62089],\n",
       "        [ 2.61539,  2.61541,  2.62911, ...,  2.6214 ,  2.61816,  2.63679]]], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data2.trn_dl.dataset.get1item(12)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.65136,  1.59942,  1.43624, ...,  0.93642,  1.17164,  0.75017],\n",
       "         [ 1.38131,  1.41287,  1.16173, ...,  0.94259,  0.8877 ,  0.11419],\n",
       "         [ 1.2332 ,  1.11449,  1.39986, ...,  0.73916,  0.68656,  0.19979],\n",
       "         ...,\n",
       "         [ 2.23416,  2.23951,  2.22591, ...,  2.23541,  2.23908,  2.22926],\n",
       "         [ 2.22168,  2.23207,  2.22627, ...,  2.23016,  2.23426,  2.22651],\n",
       "         [ 2.22473,  2.22475,  2.23496, ...,  2.23063,  2.22432,  2.23869]],\n",
       "\n",
       "        [[ 0.9711 ,  0.93752,  0.5783 , ..., -0.31907,  0.08526, -0.34831],\n",
       "         [ 0.45204,  0.40131,  0.08633, ..., -0.32827, -0.38344, -1.0391 ],\n",
       "         [ 0.16897,  0.02024,  0.54729, ..., -0.57599, -0.60046, -1.01487],\n",
       "         ...,\n",
       "         [ 2.41349,  2.41896,  2.40506, ...,  2.41477,  2.41852,  2.40848],\n",
       "         [ 2.40074,  2.41136,  2.40279, ...,  2.4094 ,  2.41046,  2.39499],\n",
       "         [ 2.40386,  2.40387,  2.40569, ...,  2.40989,  2.39188,  2.38945]],\n",
       "\n",
       "        [[ 2.14987,  2.10124,  1.96512, ...,  1.58498,  1.80771,  1.10032],\n",
       "         [ 1.92498,  1.99289,  1.72249, ...,  1.57641,  1.47394,  0.37272],\n",
       "         [ 1.83021,  1.64149,  1.90784, ...,  1.28897,  1.18914,  0.44842],\n",
       "         ...,\n",
       "         [ 2.62499,  2.63043,  2.6166 , ...,  2.62626,  2.63   ,  2.62   ],\n",
       "         [ 2.61229,  2.62287,  2.61758, ...,  2.62091,  2.62525,  2.62089],\n",
       "         [ 2.61539,  2.61541,  2.62911, ...,  2.6214 ,  2.61816,  2.63679]]]], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.trn_dl.get_batch([12])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
